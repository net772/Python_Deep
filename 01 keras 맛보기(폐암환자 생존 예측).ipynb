{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88869a93",
   "metadata": {},
   "source": [
    "# 목표\n",
    "- 폐암환자의 생존을 예측하는 모델을 만들어보자!\n",
    "- 신경망을 활용하여 2진분류 문제를 해결해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3464e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7c2724f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>293</td>\n",
       "      <td>1</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.88</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.06</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2.21</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>98</td>\n",
       "      <td>6</td>\n",
       "      <td>3.04</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>369</td>\n",
       "      <td>6</td>\n",
       "      <td>3.88</td>\n",
       "      <td>2.72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>406</td>\n",
       "      <td>6</td>\n",
       "      <td>5.36</td>\n",
       "      <td>3.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>4.32</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>447</td>\n",
       "      <td>8</td>\n",
       "      <td>5.20</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>470 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1     2     3   4   5   6   7   8   9   10  11  12  13  14  15  16  \\\n",
       "0    293   1  3.80  2.80   0   0   0   0   0   0  12   0   0   0   1   0  62   \n",
       "1      1   2  2.88  2.16   1   0   0   0   1   1  14   0   0   0   1   0  60   \n",
       "2      8   2  3.19  2.50   1   0   0   0   1   0  11   0   0   1   1   0  66   \n",
       "3     14   2  3.98  3.06   2   0   0   0   1   1  14   0   0   0   1   0  80   \n",
       "4     17   2  2.21  1.88   0   0   1   0   0   0  12   0   0   0   1   0  56   \n",
       "..   ...  ..   ...   ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..   \n",
       "465   98   6  3.04  2.40   2   0   0   0   1   0  11   0   0   0   1   0  76   \n",
       "466  369   6  3.88  2.72   1   0   0   0   1   0  12   0   0   0   1   0  77   \n",
       "467  406   6  5.36  3.96   1   0   0   0   1   0  12   0   0   0   0   0  62   \n",
       "468   25   8  4.32  3.20   0   0   0   0   0   0  11   0   0   0   0   0  58   \n",
       "469  447   8  5.20  4.10   0   0   0   0   0   0  12   0   0   0   0   0  49   \n",
       "\n",
       "     17  \n",
       "0     0  \n",
       "1     0  \n",
       "2     1  \n",
       "3     1  \n",
       "4     0  \n",
       "..   ..  \n",
       "465   0  \n",
       "466   0  \n",
       "467   0  \n",
       "468   1  \n",
       "469   0  \n",
       "\n",
       "[470 rows x 18 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# header : 데이터프레임에서 컬럼명을 설정해주는 함수(None : 인덱스 번호로 출력)\n",
    "data = pd.read_csv(\"DataFiles/ThoraricSurgery.csv\", header=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8033ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(470, 18)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e47e838",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1]   #[행의범위, 열의범위]\n",
    "y = data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "810adcab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((470, 17), (470,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b91fc687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48932af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a4c44b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(352, 17)\n",
      "(118, 17)\n",
      "(352,)\n",
      "(118,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0784177d",
   "metadata": {},
   "source": [
    "# keras를 활용하여 딥러닝 신경망을 구성해보자!\n",
    "- 1. 신경망 구조 설계\n",
    "- 2. 학습/평가방법 설정\n",
    "- 3. 학습 + 시각화\n",
    "- 4. 모델평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5286559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34512548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                180       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 66        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 28        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 279\n",
      "Trainable params: 279\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#1. 신경망 구조 설계\n",
    "model = Sequential()\n",
    "\n",
    "# 입력층(input_dim) + 중간층(Dense)\n",
    "# 첫 입력층(데이터의 특성 개수) input_dim(17) , 10(다음 층 뉴런 10개)\n",
    "# activation : 활성화함수를 설정(들어온 자극(데이터)에 대한 응답여부를 결정하는 함수)\n",
    "\n",
    "model.add(Dense(10, input_dim=17, activation=\"sigmoid\"))\n",
    "\n",
    "# 중간층\n",
    "model.add(Dense(6, activation=\"sigmoid\")) # 하나의 층\n",
    "model.add(Dense(4, activation=\"sigmoid\")) # 하나의 층\n",
    "\n",
    "# 출력층\n",
    "# 출력층은 회귀(활성화함수x), 2진분류(sigmoid), 다중분류에 따라서 사용하는 함수가 달라짐\n",
    "model.add(Dense(1, activation=\"sigmoid\")) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ff06c5",
   "metadata": {},
   "source": [
    "## activation(활성화함수) - 자극에 대한 반응여부를 결정하는 함수\n",
    "- 1. 회귀 : linear(항등함수) -> 신경망에서 도출된 수치값을 그대로 예측에 사용\n",
    "- 2. 분류 -> 딥러닝은 선형 모델을 기반으로 하고 있기 때문에 여기서 도출된 수치 값으로는 분류 문제를 예측하기 힘듦\n",
    "    - 분류 모델은 확률 정보를 가지고 판단하는 것이 더욱 정확\n",
    "    - 이진분류 : sigmoid -> 0또는 1로 분류(0.5를 기준으로 높고 낮은지에 대한 확률 정보를 바탕으로 최종 출력을 결정)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d22c5",
   "metadata": {},
   "source": [
    "### 신경망 학습/평가 방법 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71f6357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 학습 / 평가 방법 설정\n",
    "# binary_crossentropy : 2진분류에 사용하는 손실함수(비용함수)\n",
    "# -> 오차의 평균을 구하는것은 mse와 같지만 0~1사이 값으로 변환 후 평균오차를 구함\n",
    "# \n",
    "model.compile(loss=\"binary_crossentropy\",  \n",
    "             optimizer = \"SGD\",   # 최적화 함수 : 확률적경사하강법 사용\n",
    "              metrics=[\"acc\"]      # metrics : 평가방법을 설정 (정확도 체크)\n",
    "                                    # 분류 문제이기 때문에 정확도를 확인\n",
    "             )\n",
    "\n",
    "# 회귀는 오차만 확인하면 되지만 분류는 정확도까지 확인해줘야 함!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077c97bc",
   "metadata": {},
   "source": [
    "###  학습 및 학습과정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6b2fcc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 352 samples\n",
      "Epoch 1/100\n",
      "352/352 [==============================] - 1s 3ms/sample - loss: 0.5992 - acc: 0.8580\n",
      "Epoch 2/100\n",
      "352/352 [==============================] - 0s 59us/sample - loss: 0.5792 - acc: 0.8580\n",
      "Epoch 3/100\n",
      "352/352 [==============================] - 0s 71us/sample - loss: 0.5615 - acc: 0.8580\n",
      "Epoch 4/100\n",
      "352/352 [==============================] - 0s 65us/sample - loss: 0.5458 - acc: 0.8580\n",
      "Epoch 5/100\n",
      "352/352 [==============================] - 0s 60us/sample - loss: 0.5319 - acc: 0.8580\n",
      "Epoch 6/100\n",
      "352/352 [==============================] - 0s 68us/sample - loss: 0.5195 - acc: 0.8580\n",
      "Epoch 7/100\n",
      "352/352 [==============================] - 0s 60us/sample - loss: 0.5086 - acc: 0.8580\n",
      "Epoch 8/100\n",
      "352/352 [==============================] - 0s 60us/sample - loss: 0.4988 - acc: 0.8580\n",
      "Epoch 9/100\n",
      "352/352 [==============================] - 0s 68us/sample - loss: 0.4901 - acc: 0.8580\n",
      "Epoch 10/100\n",
      "352/352 [==============================] - 0s 54us/sample - loss: 0.4822 - acc: 0.8580\n",
      "Epoch 11/100\n",
      "352/352 [==============================] - 0s 63us/sample - loss: 0.4753 - acc: 0.8580\n",
      "Epoch 12/100\n",
      "352/352 [==============================] - 0s 71us/sample - loss: 0.4691 - acc: 0.8580\n",
      "Epoch 13/100\n",
      "352/352 [==============================] - 0s 60us/sample - loss: 0.4634 - acc: 0.8580\n",
      "Epoch 14/100\n",
      "352/352 [==============================] - 0s 62us/sample - loss: 0.4584 - acc: 0.8580\n",
      "Epoch 15/100\n",
      "352/352 [==============================] - 0s 68us/sample - loss: 0.4539 - acc: 0.8580\n",
      "Epoch 16/100\n",
      "352/352 [==============================] - 0s 54us/sample - loss: 0.4499 - acc: 0.8580\n",
      "Epoch 17/100\n",
      "352/352 [==============================] - 0s 68us/sample - loss: 0.4461 - acc: 0.8580\n",
      "Epoch 18/100\n",
      "352/352 [==============================] - 0s 65us/sample - loss: 0.4428 - acc: 0.8580\n",
      "Epoch 19/100\n",
      "352/352 [==============================] - 0s 60us/sample - loss: 0.4398 - acc: 0.8580\n",
      "Epoch 20/100\n",
      "352/352 [==============================] - 0s 68us/sample - loss: 0.4371 - acc: 0.8580\n",
      "Epoch 21/100\n",
      "352/352 [==============================] - 0s 63us/sample - loss: 0.4346 - acc: 0.8580\n",
      "Epoch 22/100\n",
      "352/352 [==============================] - 0s 65us/sample - loss: 0.4324 - acc: 0.8580\n",
      "Epoch 23/100\n",
      "352/352 [==============================] - 0s 57us/sample - loss: 0.4304 - acc: 0.8580\n",
      "Epoch 24/100\n",
      "352/352 [==============================] - 0s 60us/sample - loss: 0.4285 - acc: 0.8580\n",
      "Epoch 25/100\n",
      "352/352 [==============================] - 0s 51us/sample - loss: 0.4269 - acc: 0.8580\n",
      "Epoch 26/100\n",
      "352/352 [==============================] - 0s 57us/sample - loss: 0.4253 - acc: 0.8580\n",
      "Epoch 27/100\n",
      "352/352 [==============================] - 0s 57us/sample - loss: 0.4239 - acc: 0.8580\n",
      "Epoch 28/100\n",
      "352/352 [==============================] - 0s 54us/sample - loss: 0.4227 - acc: 0.8580\n",
      "Epoch 29/100\n",
      "352/352 [==============================] - 0s 62us/sample - loss: 0.4215 - acc: 0.8580\n",
      "Epoch 30/100\n",
      "352/352 [==============================] - 0s 65us/sample - loss: 0.4205 - acc: 0.8580\n",
      "Epoch 31/100\n",
      "352/352 [==============================] - 0s 57us/sample - loss: 0.4195 - acc: 0.8580\n",
      "Epoch 32/100\n",
      "352/352 [==============================] - 0s 62us/sample - loss: 0.4187 - acc: 0.8580\n",
      "Epoch 33/100\n",
      "352/352 [==============================] - 0s 65us/sample - loss: 0.4178 - acc: 0.8580\n",
      "Epoch 34/100\n",
      "352/352 [==============================] - 0s 57us/sample - loss: 0.4171 - acc: 0.8580\n",
      "Epoch 35/100\n",
      "352/352 [==============================] - 0s 71us/sample - loss: 0.4164 - acc: 0.8580\n",
      "Epoch 36/100\n",
      "352/352 [==============================] - 0s 65us/sample - loss: 0.4158 - acc: 0.8580\n",
      "Epoch 37/100\n",
      "352/352 [==============================] - 0s 60us/sample - loss: 0.4152 - acc: 0.8580\n",
      "Epoch 38/100\n",
      "352/352 [==============================] - 0s 68us/sample - loss: 0.4147 - acc: 0.8580\n",
      "Epoch 39/100\n",
      "352/352 [==============================] - 0s 57us/sample - loss: 0.4142 - acc: 0.8580\n",
      "Epoch 40/100\n",
      "352/352 [==============================] - 0s 54us/sample - loss: 0.4138 - acc: 0.8580\n",
      "Epoch 41/100\n",
      "352/352 [==============================] - 0s 68us/sample - loss: 0.4134 - acc: 0.8580\n",
      "Epoch 42/100\n",
      "352/352 [==============================] - 0s 65us/sample - loss: 0.4131 - acc: 0.8580\n",
      "Epoch 43/100\n",
      "352/352 [==============================] - 0s 54us/sample - loss: 0.4127 - acc: 0.8580\n",
      "Epoch 44/100\n",
      "352/352 [==============================] - 0s 65us/sample - loss: 0.4124 - acc: 0.8580\n",
      "Epoch 45/100\n",
      "352/352 [==============================] - 0s 57us/sample - loss: 0.4121 - acc: 0.8580\n",
      "Epoch 46/100\n",
      "352/352 [==============================] - 0s 65us/sample - loss: 0.4118 - acc: 0.8580\n",
      "Epoch 47/100\n",
      "352/352 [==============================] - 0s 65us/sample - loss: 0.4116 - acc: 0.8580\n",
      "Epoch 48/100\n",
      "352/352 [==============================] - 0s 57us/sample - loss: 0.4114 - acc: 0.8580\n",
      "Epoch 49/100\n",
      "352/352 [==============================] - 0s 62us/sample - loss: 0.4111 - acc: 0.8580\n",
      "Epoch 50/100\n",
      "352/352 [==============================] - 0s 63us/sample - loss: 0.4109 - acc: 0.8580\n",
      "Epoch 51/100\n",
      "352/352 [==============================] - 0s 57us/sample - loss: 0.4107 - acc: 0.8580\n",
      "Epoch 52/100\n",
      "352/352 [==============================] - 0s 62us/sample - loss: 0.4106 - acc: 0.8580\n",
      "Epoch 53/100\n",
      "352/352 [==============================] - 0s 65us/sample - loss: 0.4105 - acc: 0.8580\n",
      "Epoch 54/100\n",
      "352/352 [==============================] - 0s 65us/sample - loss: 0.4102 - acc: 0.8580\n",
      "Epoch 55/100\n",
      "352/352 [==============================] - 0s 62us/sample - loss: 0.4101 - acc: 0.8580\n",
      "Epoch 56/100\n",
      "352/352 [==============================] - 0s 71us/sample - loss: 0.4100 - acc: 0.8580\n",
      "Epoch 57/100\n",
      "352/352 [==============================] - 0s 54us/sample - loss: 0.4098 - acc: 0.8580\n",
      "Epoch 58/100\n",
      "352/352 [==============================] - 0s 51us/sample - loss: 0.4097 - acc: 0.8580\n",
      "Epoch 59/100\n",
      "352/352 [==============================] - 0s 57us/sample - loss: 0.4096 - acc: 0.8580\n",
      "Epoch 60/100\n",
      "352/352 [==============================] - 0s 57us/sample - loss: 0.4096 - acc: 0.8580\n",
      "Epoch 61/100\n",
      "352/352 [==============================] - 0s 63us/sample - loss: 0.4094 - acc: 0.8580\n",
      "Epoch 62/100\n",
      "352/352 [==============================] - 0s 45us/sample - loss: 0.4094 - acc: 0.8580\n",
      "Epoch 63/100\n",
      "352/352 [==============================] - 0s 62us/sample - loss: 0.4093 - acc: 0.8580\n",
      "Epoch 64/100\n",
      "352/352 [==============================] - 0s 62us/sample - loss: 0.4092 - acc: 0.8580\n",
      "Epoch 65/100\n",
      "352/352 [==============================] - 0s 62us/sample - loss: 0.4092 - acc: 0.8580\n",
      "Epoch 66/100\n",
      "352/352 [==============================] - 0s 62us/sample - loss: 0.4091 - acc: 0.8580\n",
      "Epoch 67/100\n",
      "352/352 [==============================] - 0s 65us/sample - loss: 0.4091 - acc: 0.8580\n",
      "Epoch 68/100\n",
      "352/352 [==============================] - 0s 57us/sample - loss: 0.4091 - acc: 0.8580\n",
      "Epoch 69/100\n",
      "352/352 [==============================] - 0s 60us/sample - loss: 0.4090 - acc: 0.8580\n",
      "Epoch 70/100\n",
      "352/352 [==============================] - 0s 60us/sample - loss: 0.4089 - acc: 0.8580\n",
      "Epoch 71/100\n",
      "352/352 [==============================] - 0s 57us/sample - loss: 0.4089 - acc: 0.8580\n",
      "Epoch 72/100\n",
      "352/352 [==============================] - 0s 62us/sample - loss: 0.4089 - acc: 0.8580\n",
      "Epoch 73/100\n",
      "352/352 [==============================] - 0s 62us/sample - loss: 0.4088 - acc: 0.8580\n",
      "Epoch 74/100\n",
      "352/352 [==============================] - 0s 57us/sample - loss: 0.4088 - acc: 0.8580\n",
      "Epoch 75/100\n",
      "352/352 [==============================] - 0s 65us/sample - loss: 0.4088 - acc: 0.8580\n",
      "Epoch 76/100\n",
      "352/352 [==============================] - 0s 68us/sample - loss: 0.4087 - acc: 0.8580\n",
      "Epoch 77/100\n",
      "352/352 [==============================] - 0s 60us/sample - loss: 0.4087 - acc: 0.8580\n",
      "Epoch 78/100\n",
      "352/352 [==============================] - 0s 68us/sample - loss: 0.4087 - acc: 0.8580\n",
      "Epoch 79/100\n",
      "352/352 [==============================] - 0s 60us/sample - loss: 0.4087 - acc: 0.8580\n",
      "Epoch 80/100\n",
      "352/352 [==============================] - 0s 60us/sample - loss: 0.4087 - acc: 0.8580\n",
      "Epoch 81/100\n",
      "352/352 [==============================] - 0s 63us/sample - loss: 0.4086 - acc: 0.8580\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 0s 60us/sample - loss: 0.4086 - acc: 0.8580\n",
      "Epoch 83/100\n",
      "352/352 [==============================] - 0s 60us/sample - loss: 0.4086 - acc: 0.8580\n",
      "Epoch 84/100\n",
      "352/352 [==============================] - 0s 63us/sample - loss: 0.4086 - acc: 0.8580\n",
      "Epoch 85/100\n",
      "352/352 [==============================] - 0s 57us/sample - loss: 0.4086 - acc: 0.8580\n",
      "Epoch 86/100\n",
      "352/352 [==============================] - 0s 62us/sample - loss: 0.4086 - acc: 0.8580\n",
      "Epoch 87/100\n",
      "352/352 [==============================] - 0s 68us/sample - loss: 0.4086 - acc: 0.8580\n",
      "Epoch 88/100\n",
      "352/352 [==============================] - 0s 51us/sample - loss: 0.4085 - acc: 0.8580\n",
      "Epoch 89/100\n",
      "352/352 [==============================] - 0s 60us/sample - loss: 0.4086 - acc: 0.8580\n",
      "Epoch 90/100\n",
      "352/352 [==============================] - 0s 65us/sample - loss: 0.4085 - acc: 0.8580\n",
      "Epoch 91/100\n",
      "352/352 [==============================] - 0s 62us/sample - loss: 0.4085 - acc: 0.8580\n",
      "Epoch 92/100\n",
      "352/352 [==============================] - 0s 62us/sample - loss: 0.4085 - acc: 0.8580\n",
      "Epoch 93/100\n",
      "352/352 [==============================] - 0s 63us/sample - loss: 0.4085 - acc: 0.8580\n",
      "Epoch 94/100\n",
      "352/352 [==============================] - 0s 63us/sample - loss: 0.4085 - acc: 0.8580\n",
      "Epoch 95/100\n",
      "352/352 [==============================] - 0s 62us/sample - loss: 0.4085 - acc: 0.8580\n",
      "Epoch 96/100\n",
      "352/352 [==============================] - 0s 57us/sample - loss: 0.4085 - acc: 0.8580\n",
      "Epoch 97/100\n",
      "352/352 [==============================] - 0s 57us/sample - loss: 0.4086 - acc: 0.8580\n",
      "Epoch 98/100\n",
      "352/352 [==============================] - 0s 60us/sample - loss: 0.4085 - acc: 0.8580\n",
      "Epoch 99/100\n",
      "352/352 [==============================] - 0s 60us/sample - loss: 0.4085 - acc: 0.8580\n",
      "Epoch 100/100\n",
      "352/352 [==============================] - 0s 62us/sample - loss: 0.4085 - acc: 0.8580\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(X_train, y_train, epochs=100) # epochs : 학습 횟수를 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c39af9e",
   "metadata": {},
   "source": [
    "### 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c59b8f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a4afd17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 시각화\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "# 라인 차트를 생성\n",
    "plt.plot(range(1,101),  # epochs 가 100까지 설정을 했기 때문에\n",
    "            h.history['acc'],    # history : 학습시 출력되는 loss 혹은 정확도 값을 가져오기 위한 명령\n",
    "            label='acc')\n",
    "plt.legend() # 범례표시\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed922a35",
   "metadata": {},
   "source": [
    "### 모델평가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6ce3825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 0s 307us/sample - loss: 0.4571 - acc: 0.8305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4571263123366792, 0.8305085]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3e8b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
