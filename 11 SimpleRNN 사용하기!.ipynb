{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f858d5a",
   "metadata": {},
   "source": [
    "### 간단한 데이터를 만들어서 RNN의 구조를 익혀보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82806578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964a5679",
   "metadata": {},
   "source": [
    "#### 데이터셋 구축하기\n",
    "- 글자 하나하나 단위로 RNN을 사용해보자!\n",
    "- hello, apple, lobby, daddy, bobby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3aa43ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 데이터는 hell, appl, lobb,dadd, bobb\n",
    "# 정답 데이터는 o, e, y, y, y\n",
    "\n",
    "# timesteps는 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50abf9f",
   "metadata": {},
   "source": [
    "#### 원핫인코딩으로 문자를 숫자로 변경\n",
    "\n",
    "- 문제 + 정답 전체 데이터에서 등장하는 문자는 h, e, l, o, a, p, b, y, d 로 총 9개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24a05eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN 데이터 구조파악을 위해 원핫인코딩을 직접 해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "494ff74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 데이터\n",
    "X_train = np.array(\n",
    "    [\n",
    "        # 각각의 단어들\n",
    "        [[1,0,0,0,0,0,0,0,0],[0,1,0,0,0,0,0,0,0],[0,0,1,0,0,0,0,0,0],[0,0,1,0,0,0,0,0,0]],           \n",
    "        [[0,0,0,0,1,0,0,0,0],[0,0,0,0,0,1,0,0,0],[0,0,0,0,0,1,0,0,0],[0,0,1,0,0,0,0,0,0]],\n",
    "        [[0,0,1,0,0,0,0,0,0],[0,0,0,1,0,0,0,0,0],[0,0,0,0,0,0,1,0,0],[0,0,0,0,0,0,1,0,0]],\n",
    "        [[0,0,0,0,0,0,0,0,1],[0,0,0,0,1,0,0,0,0],[0,0,0,0,0,0,0,0,1],[0,0,0,0,0,0,0,0,1]],\n",
    "        [[0,0,0,0,0,0,1,0,0],[0,0,0,1,0,0,0,0,0],[0,0,0,0,0,0,1,0,0],[0,0,0,0,0,0,1,0,0]]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "747c5464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답 데이터\n",
    "y_train = np.array(\n",
    "    [\n",
    "        [0,0,0,1,0,0,0,0,0],\n",
    "        [0,1,0,0,0,0,0,0,0],\n",
    "        [0,0,0,0,0,0,0,1,0],\n",
    "        [0,0,0,0,0,0,0,1,0],\n",
    "        [0,0,0,0,0,0,0,1,0]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc6bf5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 4, 9), (5, 9))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape\n",
    "# samples(샘플수), timesteps(순환횟수), features(정답에 들어갈 수 있는 숫자의 개수 = 원핫인코딩된 레이블 수)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496fa7b3",
   "metadata": {},
   "source": [
    "#### 출력되는 값을 알파벳 전체로 하고 싶다면 26개로 원핫 인코딩 하면 됨\n",
    " - 현재는 RNN을 알아보기 위해 간단히 9개의 단어로만 문제와 정답을 설정함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b75f53",
   "metadata": {},
   "source": [
    "### RNN 신경망 모델링 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26a0539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b609015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, 8)                 144       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 9)                 81        \n",
      "=================================================================\n",
      "Total params: 225\n",
      "Trainable params: 225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# 입력층 + 중간층\n",
    "# 8개의 뉴런을 가지고 각 뉴련이 4번씩 순환하며 각 순환마다 9개의 숫자가 들어감\n",
    "#  timesteps(순환횟수), features(원핫인코딩)\n",
    "model.add(SimpleRNN(8, input_shape=(4,9)))  \n",
    "\n",
    "# 출력층\n",
    "# 사용되는 단어가 총 9개이고 정답도 거기에 포함이 되어있음(다중분류와 같음)\n",
    "model.add(Dense(9, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# RNN은 가중치가 두 종류가 있음(과거데이터의 가중치, 현재데이터의 가중치)\n",
    "# 현재데이터의 가중치 -> 9(입력특성) * 8(RNN층 뉴런 수) + 8(Rnn층 뉴런수)\n",
    "# 과거데이터의 가중치 -> 8(RNN층 뉴런 수) * 8(RNN층 뉴런수)\n",
    "# RNN층의 각 뉴런들이 뽑아낸 겨로가는 다시 모든 뉴런들에게 과거데이터로 들어가게됨\n",
    "# (순환횟수와는 상관없이 최종 결과값에 대한 가중치를 카운트)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "558309c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='Adam',\n",
    "             metrics=['acc']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e83a35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5 samples\n",
      "Epoch 1/200\n",
      "5/5 [==============================] - 1s 263ms/sample - loss: 2.6466 - acc: 0.0000e+00\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 3ms/sample - loss: 2.6324 - acc: 0.0000e+00\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 998us/sample - loss: 2.6183 - acc: 0.0000e+00\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 2.6043 - acc: 0.0000e+00\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 795us/sample - loss: 2.5903 - acc: 0.0000e+00\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 2.5765 - acc: 0.0000e+00\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 2.5628 - acc: 0.0000e+00\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 928us/sample - loss: 2.5491 - acc: 0.0000e+00\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 801us/sample - loss: 2.5356 - acc: 0.0000e+00\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 2.5222 - acc: 0.0000e+00\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 2.5088 - acc: 0.0000e+00\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 2.4956 - acc: 0.0000e+00\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 2.4824 - acc: 0.0000e+00\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 2.4694 - acc: 0.0000e+00\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 2.4565 - acc: 0.0000e+00\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 2.4436 - acc: 0.0000e+00\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 2.4309 - acc: 0.0000e+00\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 2.4182 - acc: 0.0000e+00\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 2.4056 - acc: 0.0000e+00\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 2.3932 - acc: 0.0000e+00\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 2.3808 - acc: 0.0000e+00\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 1000us/sample - loss: 2.3685 - acc: 0.0000e+00\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 2.3563 - acc: 0.0000e+00\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 2.3442 - acc: 0.0000e+00\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 2.3321 - acc: 0.0000e+00\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 746us/sample - loss: 2.3201 - acc: 0.0000e+00\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 850us/sample - loss: 2.3082 - acc: 0.0000e+00\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 2.2964 - acc: 0.0000e+00\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 1000us/sample - loss: 2.2847 - acc: 0.0000e+00\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 2.2730 - acc: 0.0000e+00\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 807us/sample - loss: 2.2613 - acc: 0.0000e+00\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 2.2498 - acc: 0.0000e+00\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 2.2383 - acc: 0.0000e+00\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 2.2268 - acc: 0.0000e+00\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 1000us/sample - loss: 2.2154 - acc: 0.0000e+00\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 2.2040 - acc: 0.0000e+00\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 2.1927 - acc: 0.0000e+00\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 2.1815 - acc: 0.0000e+00\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 2.1703 - acc: 0.0000e+00\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 2.1591 - acc: 0.0000e+00\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 2.1480 - acc: 0.0000e+00\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 2.1369 - acc: 0.0000e+00\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 2.1258 - acc: 0.0000e+00\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 2.1148 - acc: 0.0000e+00\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 2.1038 - acc: 0.0000e+00\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 2.0929 - acc: 0.0000e+00\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 2.0820 - acc: 0.0000e+00\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 2.0711 - acc: 0.0000e+00\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 2.0602 - acc: 0.0000e+00\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 2.0494 - acc: 0.2000\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 2.0386 - acc: 0.2000\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 2.0278 - acc: 0.2000\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 2.0170 - acc: 0.2000\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 2.0063 - acc: 0.2000\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.9956 - acc: 0.2000\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 1.9849 - acc: 0.2000\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 1.9742 - acc: 0.2000\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.9636 - acc: 0.2000\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.9529 - acc: 0.4000\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.9423 - acc: 0.4000\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.9317 - acc: 0.4000\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 1.9212 - acc: 0.4000\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 1.9106 - acc: 0.4000\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.9001 - acc: 0.6000\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 1.8896 - acc: 0.6000\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.8791 - acc: 0.6000\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.8687 - acc: 0.6000\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 1.8582 - acc: 0.6000\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 798us/sample - loss: 1.8478 - acc: 0.6000\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.8374 - acc: 0.6000\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 1.8271 - acc: 0.6000\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.8167 - acc: 0.6000\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 601us/sample - loss: 1.8064 - acc: 0.6000\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.7960 - acc: 0.6000\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.7858 - acc: 0.6000\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.7755 - acc: 0.6000\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.7652 - acc: 0.6000\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.7550 - acc: 0.6000\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.7448 - acc: 0.6000\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.7346 - acc: 0.6000\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.7245 - acc: 0.8000\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.7143 - acc: 0.8000\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 1.7042 - acc: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 1.6941 - acc: 0.8000\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 1.6841 - acc: 0.8000\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.6740 - acc: 0.8000\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.6640 - acc: 0.8000\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 1.6540 - acc: 0.8000\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.6440 - acc: 0.8000\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.6341 - acc: 0.8000\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.6242 - acc: 0.8000\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.6143 - acc: 0.8000\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.6044 - acc: 0.8000\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 1.5946 - acc: 0.8000\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 1.5847 - acc: 0.8000\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 1.5749 - acc: 0.8000\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 1.5652 - acc: 0.8000\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.5555 - acc: 0.8000\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 1.5457 - acc: 0.8000\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 1.5361 - acc: 0.8000\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.5264 - acc: 0.8000\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.5168 - acc: 0.8000\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.5072 - acc: 0.8000\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.4976 - acc: 0.8000\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 1.4881 - acc: 0.8000\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 799us/sample - loss: 1.4786 - acc: 0.8000\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 1.4691 - acc: 0.8000\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.4597 - acc: 0.8000\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 1.4503 - acc: 0.8000\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.4409 - acc: 0.8000\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.4315 - acc: 0.8000\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 1.4222 - acc: 0.8000\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 999us/sample - loss: 1.4129 - acc: 0.8000\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 1.4037 - acc: 0.8000\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 1000us/sample - loss: 1.3944 - acc: 0.8000\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 803us/sample - loss: 1.3853 - acc: 0.8000\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 797us/sample - loss: 1.3761 - acc: 0.8000\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.3670 - acc: 0.8000\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 1000us/sample - loss: 1.3579 - acc: 0.8000\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.3489 - acc: 0.8000\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.3399 - acc: 0.8000\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.3309 - acc: 0.8000\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 801us/sample - loss: 1.3219 - acc: 0.8000\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 799us/sample - loss: 1.3130 - acc: 0.8000\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.3042 - acc: 0.8000\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 1.2954 - acc: 0.8000\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.2866 - acc: 0.8000\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.2778 - acc: 0.8000\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.2691 - acc: 0.8000\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.2604 - acc: 0.8000\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 1.2518 - acc: 0.8000\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 1.2432 - acc: 0.8000\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.2347 - acc: 0.8000\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.2261 - acc: 0.8000\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 1.2177 - acc: 0.8000\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 1.2092 - acc: 0.8000\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 1.2008 - acc: 0.8000\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 1.1925 - acc: 0.8000\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.1842 - acc: 0.8000\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.1759 - acc: 0.8000\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 802us/sample - loss: 1.1677 - acc: 0.8000\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 802us/sample - loss: 1.1595 - acc: 0.8000\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.1514 - acc: 0.8000\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.1433 - acc: 0.8000\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.1352 - acc: 0.8000\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.1272 - acc: 0.8000\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 1.1192 - acc: 0.8000\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 1.1113 - acc: 0.8000\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 1.1034 - acc: 0.8000\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.0955 - acc: 0.8000\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.0877 - acc: 0.8000\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.0799 - acc: 0.8000\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 1.0722 - acc: 0.8000\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.0645 - acc: 0.8000\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 1.0569 - acc: 0.8000\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.0493 - acc: 0.8000\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.0418 - acc: 0.8000\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.0342 - acc: 0.8000\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.0268 - acc: 0.8000\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 1.0193 - acc: 0.8000\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 1.0120 - acc: 0.8000\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 804us/sample - loss: 1.0046 - acc: 0.8000\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 802us/sample - loss: 0.9973 - acc: 0.8000\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 797us/sample - loss: 0.9901 - acc: 0.8000\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 0.9828 - acc: 0.8000\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 0.9757 - acc: 0.8000\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 0.9685 - acc: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 0.9614 - acc: 0.8000\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 0.9544 - acc: 0.8000\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 0.9473 - acc: 0.8000\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 1000us/sample - loss: 0.9404 - acc: 0.8000\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 0.9334 - acc: 0.8000\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 0.9265 - acc: 0.8000\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 0.9197 - acc: 0.8000\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 0.9129 - acc: 1.0000\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 0.9061 - acc: 1.0000\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 0.8994 - acc: 1.0000\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 0.8927 - acc: 1.0000\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 1000us/sample - loss: 0.8860 - acc: 1.0000\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 0.8794 - acc: 1.0000\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 0.8728 - acc: 1.0000\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 0.8663 - acc: 1.0000\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 0.8598 - acc: 1.0000\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 801us/sample - loss: 0.8533 - acc: 1.0000\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 0.8469 - acc: 1.0000\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 1000us/sample - loss: 0.8405 - acc: 1.0000\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 1000us/sample - loss: 0.8342 - acc: 1.0000\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 0.8278 - acc: 1.0000\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 0.8216 - acc: 1.0000\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 998us/sample - loss: 0.8153 - acc: 1.0000\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 0.8091 - acc: 1.0000\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 999us/sample - loss: 0.8030 - acc: 1.0000\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 0.7968 - acc: 1.0000\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 0.7907 - acc: 1.0000\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 802us/sample - loss: 0.7847 - acc: 1.0000\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 0.7787 - acc: 1.0000\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 1000us/sample - loss: 0.7727 - acc: 1.0000\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 800us/sample - loss: 0.7667 - acc: 1.0000\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 0.7608 - acc: 1.0000\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 1ms/sample - loss: 0.7550 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(X_train, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37d0cb15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(range(1,201),\n",
    "        h.history['acc'],\n",
    "        label='acc'\n",
    "        )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2808f573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
